name: Merolagani Scraper

on:
  schedule:
    # Run daily at 6:00 AM UTC (adjust time as needed)
    - cron: '0 6 * * *'
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Increase timeout to 60 minutes
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas pyarrow
    
    - name: Configure system for better performance
      run: |
        # Make more memory available by disabling unnecessary services
        sudo systemctl stop snapd snapd.socket snapd.seeded
        sudo systemctl disable snapd snapd.socket snapd.seeded
        
        # Display available system resources
        free -h
        nproc
        
        # Create output directories and make them writable
        mkdir -p temp_data
        mkdir -p public/floorsheet_data
        chmod -R 777 temp_data public
    
    - name: Run scraper
      run: |
        # Set environment variables to optimize Python memory usage
        export PYTHONUNBUFFERED=1
        export PYTHONMALLOC=malloc
        export MALLOC_TRIM_THRESHOLD_=65536
        
        # Run the script and save output to a log file
        python merolagani_scraper.py 2>&1 | tee scraper_output.log
        
        # Print directory contents for debugging
        echo "Current directory contents:"
        ls -la
        echo "public directory contents:"
        ls -la public || echo "Directory doesn't exist"
        echo "public/floorsheet_data directory contents:"
        ls -la public/floorsheet_data || echo "Directory doesn't exist"
    
    - name: Commit files to repository
      run: |
        git config --global user.name 'github-actions'
        git config --global user.email 'github-actions@github.com'
        
        # Add all files in the public directory
        git add public/
        
        # Commit and push the changes
        git commit -m "Update floorsheet data $(date +'%Y-%m-%d')" || echo "No changes to commit"
        git push
    
    - name: Upload scraped data
      uses: actions/upload-artifact@v4
      with:
        name: floorsheet-data
        path: |
          public/floorsheet_data/
          public/floorsheet_data/*
          public/floorsheet_data/**/*
        retention-days: 7
        if-no-files-found: warn
